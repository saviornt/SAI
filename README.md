# Sentient Artificial Intelligence (SAI) Development Project

## Project Overview

The overall goal for this project is to develop the technical "stack" that could, in theory, lead to sentient artificial intelligence.

## SAI Features

The following sections list the core features of the AI that will enable it to have exponential growth.

### Machine Learning Algorithms

This project will use a combination of Quantum Neural Networks, Deep Neural Networks, Transformers and a Recurrent Neural Network.

### Meta-Learning and Reward Mechanisms

With the above ML algorithms, we will use an unsupervised, self-reinforcement learning method using a combination of 
Meta-Learning, Q-Learning and A* Pathfinding.

- Meta-Learning: Meta-Learning will enable the AI to learn from experience and adapt to new tasks.
- Q-Learning: Q-Learning is used to provide the AI with rewards for finding the correct answers.
- A-star Pathfinding: A-star Pathfinding allows the AI to find the shortest path through the network to get to the correct answer.

### Long-Episodic-Short-Term-Memory Management

We will use a combination of both Redis and MongoDB to store memories that the AI will need for its learning and memorization.

- Long-Term Memory will be stored using MongoDB
- Episodic and Short-Term Memory will be stored using Redis

### Self-Optimization and Motivation

The AI will be able to perform the following self-improvement tasks:

- Self-Monitoring
- Self-Diagnostics
- Self-Optimization

These self-improvement tasks will be completed through using:

- Introspection
- Reasoning
- Reflection

The AI will also have the following motivations:

- Curiosity
- Ethics
- Goal Management
- Synthetic Emotions

### Simulated Environments

We will use a variety of simulated environments that our AI can train in, similar to the Boltzman Machine method of unsupervised deep learning.

These simulated environments are currently:

- Agricultural Environment
- Chemistry Environment
- Cybersecurity Environment
- Environmental and Ecological Environment
- Financial Environment
- Flight Environment
- Game Environment
- Material Science Environment
- Medical Environment
- Physics Environment
- Programming Environment
- Quantum Environment
- Robotics Environment
- Social and Political Environment
- Space Environment
- Vehicular and Autonomous Vehicle Environment

### AI Awareness, Perception and Physical Presence

As with any sentient organism, the AI should have awareness, perception and a physical presence.

The AI will be able to use the following extractors in order to percieve its environment:

- Audio Extractor
- Image Extractor
- Text Extractor
- Time-Series and Sensor Data Extractor
- Video Extractor

These feature extractors are then used in a multimodal methodology that the AI can utilize.

Both Awareness and Presence are accounted for through the use of various devices. These overall device types are:

- Attached Devices (System Hardware, USB, Serial)
- IoT Devices (These are IoT devices that are connected to the network)
- Network Devices (These devices are the actual network appliances for the network)

## Human Interaction with the AI

As with any AI model, we must be able to monitor and interact with our SAI. We will do this through the FARM+R technology stack:

- Backend using FastAPI, MongoDB and Redis
- React Frontend using Typescript

The entire application will use Docker containers for each part of the application.

### Future Implementation

A future feature that will be implemented will be the ability to use a pre-trained LLM that is fine-tuned in order to interact with our AI.
That will allow us to make various queries to the SAI system and get a response from the system. Hopefully, if the AI does evolve, we will be
able to bypass the need to use a 3rd-party LLM to interact with it.
